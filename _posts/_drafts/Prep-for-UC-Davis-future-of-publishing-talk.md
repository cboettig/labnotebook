---
layout: post
published: false

---





### Scratchpad, first go 

Literature doesn't scale.  Engagement with most content is superficial.
You can utilize only a decreasing amount of content for each paper
you add.  Software-based contributions scale.  You don't just get
the concept of a better algorithm you never have time to implement or
understand fully.  you get the algorithm.  This sounds superficial -
you can use it with no understanding.  Yet we use papers like this
all the time, when we cite papers for having showed what they claim.
Having to understand and rewrite the algorithm yourself is like saying:
don't cite anything until you have reproduced the results in your own lab.
With a key difference.  Others can critique and improve .

What about non-computational procedures?  I don't know - that stuff is
hard. The same concepts still apply - use of standards, documentation,
etc all help.  Design for replicability, because it lets these approaches
scale. But let's solve the easier problem of computational replicability
first.

People worry that 'big data' means superficial understanding of the data.
I think the opposite.  As literature grows, engagement with the details
of the data details is increasingly superficial.

People worry that data publishing is a coup for data consumers
(theorists), since they will get more publications.  I think it is a
coup for data producers, if the data truly is so excellent that anyone
can easily turn out lots of papers, it is quite clear that the data is
worth more than the papers.

The future is here. rOpenSci: eml publish data, access data, use
data. engage with researchers.  Engage with software.

Data, code are things we can interact with at scale Publishing that
scales.



### Scratchpad, second go 

Scale.


Data.

As soon as letters to society journals replaced anagrams as the means of
documenting and sharing discoveries, scientists published all the data
necessary to interpret and replicate their findings.  We replicate them
today in high-school labs.

Today's science is more complicated; all that data doesn't always fit
on 6 printed pages with four color figures.

It doesn't fit today's scientific community either.

Internet ended personal journal subscriptions; replaced by secret
library contracts of large bundles.  Thus died the market mechanisms
previously in play and lead to the consolidation of most journals
under a handful of cooperations.  Cooperate bundles and the library's
proclivity to be comprehensive in place of the individual subscriber's
desire to be selective enabled the proliferation of journals that would
not survive alone while driving out or taking over most small specialized
society journals.   To distinguish among a flood of new titles researchers
increasingly relied on measures like impact factor in place of historical
and personal impressions.  (Anything could be published _somewhere_
and more supply of papers increased the desire for filters).

Thus did the Internet revolutionize publishing into what it is today:
a handful of major international publishing companies running a
multi-billion dollar industry with the best profit margins (read least
economic efficiency) on the planet. It's a recent change in a dynamic
industry; perhaps 20 years old.  Another 40 years before that most
journals weren't conducting peer review.

Publication has changed little since the transition to library-based
subscriptions, because this situation is economically quite stable.

This scales really well in a write-only culture.

<!--
(In the 1960's, Ecologist Bob Paine once told his mother his paper had
1200 reprint requests.  She replied that she had just received 200,000
reprint requests of a small piece she had written for the NY Times.) 
So what is impact?  What is it we really want to measure?

-->

### Third Go

Reasons for optimism about change: 

- Government mandates (Finch Report, Obama Executive Order, congressional bills)
- Funders: NSF changes: data management plans, recognizes 'products' not 'papers'.  Moore & Sloan Foundation.  
- Journals: Once we worried if openness was even allowed (preprints).  Now every month we learn of new data publication requirements (ESA Apps, Monographs. British Ecological Society. All PLoS.  Dryad integrated journals. Nature Science PNAS)

These are drivers of change in an immediate sense, but also symptoms of deeper currents.  

Economics: behavior of the aggregate.  

Internet replaced the scientist-journal customer relationship with the library-journal one. This brought obvious advantages but relatively terrible side-effects to the economics: monopolies, secret deals, huge market inefficiencies (profit margins).  

Change may be slow, but no one believes that this state, less than a few decades old, will be stable for decades to come.  

Annette Thomas, Digital Science.  Platform.  

rOpenSci as platform.  

(a return to the) Publishing of data.  The publishing of code.  





