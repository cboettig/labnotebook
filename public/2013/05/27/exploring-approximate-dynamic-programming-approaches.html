<!DOCTYPE html>
<html lang="en" xmlns="https://www.w3.org/1999/xhtml" xml:lang="en">
  <head prefix="dc: https://purl.org/dc/terms/ og: http://ogp.me/ns#"> <!-- namespaces used in metadata.html -->
  <meta http-equiv='Content-Type' content='text/html; charset=utf-8'/>
  <title>Exploring Approximate Dynamic Programming Approaches</title>
  <meta name="author" content="Carl Boettiger" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <!-- HTML5 metadata -->
<meta name="keywords" content="nonparametric-bayes, algorithms" />
<meta name="description" content="" />
<!-- RDFa Metadata (in DublinCore) -->
<meta property="dc:title" content="Exploring Approximate Dynamic Programming Approaches" />
<meta property="dc:creator" content="Carl Boettiger" />
<meta property="dc:date" content="2013-05-27 00:00:00 +0000" />
<meta property="dc:format" content="text/html" />
<meta property="dc:language" content="en" />
<meta property="dc:identifier" content="/05/27/exploring-approximate-dynamic-programming-approaches.html" />
<meta property="dc:rights" content="CC0" />
<meta property="dc:source" content="Lab Notebook" />
<meta property="dc:subject" content="Ecology" /> 
<meta property="dc:type" content="website" /> 
<!-- RDFa Metadata (in OpenGraph) -->
<meta property="og:title" content="Exploring Approximate Dynamic Programming Approaches" />
<meta property="og:author" content="https://www.carlboettiger.info/index.html#me" />  <!-- Should be Liquid? URI? -->
<meta property="https://ogp.me/ns/profile#first_name" content="Carl"/>
<meta property="https://ogp.me/ns/profile#last_name" content="Boettiger"/>
<meta property="https://ogp.me/ns/article#published_time" content="2013-05-27 00:00:00 +0000" />
<meta property="og:site_name" content="Lab Notebook" /> <!-- Same as dc:source? -->
<meta property="og:url" content="https://www.carlboettiger.info/05/27/exploring-approximate-dynamic-programming-approaches.html" />
<meta property="og:type" content="website" /> 
<!-- Google Scholar Metadata -->
<!--
<meta name="citation_author" content="Carl Boettiger"/>
<meta name="citation_date" content="2013-05-27 00:00:00 +0000"/>
<meta name="citation_title" content="Exploring Approximate Dynamic Programming Approaches"/>
<meta name="citation_journal_title" content="Lab Notebook"/>
-->
<!--NOTE: see also the COinS Metadata in span element in footer -->




	<link href="https://www.carlboettiger.info/assets/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
  <link href="//netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
  <!-- Help the browser identify the RSS feed automatically -->
  <link rel="alternate" type="application/rss+xml" title="Carl Boettiger's Lab Notebook" href="/blog.xml" />
</head>


  <body prefix="dc: https://purl.org/dc/terms/ foaf: http://xmlns.com/foaf/0.1/"> 
    <!-- Navbar  ================================================== -->

<nav class="navbar navbar-default" role="navigation">
  <div class="container-fluid">
    <!-- Brand and toggle get grouped for better mobile display -->
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="/README.html"><i class="icon-info-sign"></i></a>
    </div>

 <!-- Collect the nav links, forms, and other content for toggling -->
    <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
      <ul class="nav navbar-nav">

          <li  >
          <a href="/index.html">Home</a></li>
          <li  >
          <a href="/vita.html">Vita</a></li>
          <li  >
          <a href="/research.html">Research</a></li>
          <li  >
          <a href="/teaching.html">Teaching</a></li>
          <li  >
          <a href="/community.html">Community</a></li>
          <li  >
          <a href="/lab-notebook.html">Lab Notebook</a></li>

        </ul>

      <!-- Search site using Google's index -->
        <form class="navbar-form navbar-right" role="search" method="get" action="https://google.com/search">
          <div class="form-group">
            <input type="hidden" name="q" value="site:carlboettiger.info" />
            <input type="text" class="form-control search-query" name="q" placeholder="Search"/>
          </div>
          <button class="btn btn-mini" type="submit"><i class="icon-search"></i></button> 
       </form>

    </div><!--/.nav-collapse -->
  </div> <!-- /container -->
</nav>



    <div class="container"> <!-- Responsive grid layout, doesn't jump to full-width --> 
      <header>
        <h1 class="entry-title">Exploring Approximate Dynamic Programming Approaches</h1>
        <h2></h2>
      </header>

      <div class="row">
  <div class="col-md-7 col-md-offset-1">
    <article>
    <h2 id="introductory-examples-in-approximate-dynamic-programming">Introductory examples in approximate dynamic programming</h2>
<p><em>Based on Powell 2006, page 97. I try to conform to that notation throughout</em>. Haven’t really figured this out yet, so this is more a walk through of me thinking this out then a tutorial. My active copy of this analysis can be found in the <a href="https://github.com/cboettig/nonparametric-bayes/blob/4eb6a30441f28e9cbe87690d9e098b0e068cc395/inst/examples/adp-intro.md">adp-intro</a> file of my nonparametric-bayes repo, see there for the <a href="https://github.com/cboettig/nonparametric-bayes/blob/master/inst/examples/adp-intro.md">most recent</a> (or earlier) versions.</p>
<h2 id="setup-my-sample-problem">Setup my sample problem</h2>
<p>First we define the Beverton-Holt stock-recruitment relationship as a function of stock size <code>x</code>, harvest <code>h</code> and parameters <code>p</code></p>
<pre class="sourceCode r"><code class="sourceCode r">f &lt;-<span class="st"> </span>function(x, h, p){
    A &lt;-<span class="st"> </span>p[<span class="dv">1</span>] 
    B &lt;-<span class="st"> </span>p[<span class="dv">2</span>] 
    s &lt;-<span class="st"> </span><span class="kw">pmax</span>(x-h, <span class="dv">0</span>)
    A *<span class="st"> </span>s/(<span class="dv">1</span> +<span class="st"> </span>B *<span class="st"> </span>s)
}
p &lt;-<span class="st"> </span>pars &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">1.5</span>, <span class="fl">0.5</span>)
K &lt;-<span class="st"> </span>(p[<span class="dv">1</span>] -<span class="st"> </span><span class="dv">1</span>)/p[<span class="dv">2</span>]
sigma_g &lt;-<span class="st"> </span><span class="fl">0.2</span></code></pre>
<p>We begin with a simulation method <span class="math">\(X_{t+1} = f(X_t, Z_t)\)</span>. For illustration, let us consider <span class="math">\(f(X_t, Z_t) = Z_t \frac{a X_t}{b + X_t}\)</span> with a = 1.5 and b = 0.5. We define a statespace <span class="math">\(S\)</span></p>
<pre class="sourceCode r"><code class="sourceCode r">S &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">length=</span><span class="dv">11</span>) </code></pre>
<p>as a uniform grid of 11 points from 0 to 1.<br />We also need a value function on the state space, <span class="math">\(C_t(S_t)\)</span>. For simplicity, we set the price of harvest at unity and the cost of harvesting at zero, so that <span class="math">\(C_t(S_t, x_t) = \min(x_t, S_t)\)</span>.<br />(<span class="math">\(C_t\)</span> is sometimes denoted <span class="math">\(\mathbb{\Pi}\)</span>).<br />We also need an action space <span class="math">\(\chi_t\)</span> of possible harvest values.<br />Again for simplicity we assume that harvest can be set to any possible state size, <span class="math">\(\chi_t \equiv S_t\)</span>,</p>
<pre class="sourceCode r"><code class="sourceCode r">chi &lt;-<span class="st"> </span>S</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">T &lt;-<span class="st"> </span><span class="dv">10</span>
N &lt;-<span class="st"> </span><span class="dv">10</span></code></pre>
<p>The approximate dynamic programming algorithm will perform a finite number <span class="math">\(N\)</span> = 10 iterations over a window of time <span class="math">\(T\)</span> =10 in our example. The algorithm can then be described as follows:</p>
<h2 id="algorithm-1">Algorithm (1)</h2>
<ul>
<li><p><strong>Step 0</strong></p></li>
<li><p>Initialize some value <span class="math">\(\tilde V_t^0(S_t)\)</span> for all states <span class="math">\(S_t\)</span>, where the superscripts denote iterations in the forward approximation.<br /> As we know absolutely nothing yet to base our initial guess on, we just arbitrarily set this to zero.</p></li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r">V &lt;-<span class="st"> </span><span class="kw">numeric</span>(<span class="kw">length</span>(S))</code></pre>
<ul>
<li>Choose some initial state <span class="math">\(S_0^1\)</span> We start at some initial state for <span class="math">\(n = 1\)</span> (superscript) and <span class="math">\(t = 0\)</span> (subscript). The choice of initial condition may come from the problem itself, otherwise we choose something arbitrarily.</li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r">S_0 &lt;-<span class="st"> </span><span class="fl">0.5</span></code></pre>
<ul>
<li><p>Set <span class="math">\(n = 1\)</span></p></li>
<li><p><strong>Step 1</strong>: Choose a sample path, <span class="math">\(\omega^n\)</span> (a vector of random draws)</p></li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r">sigma &lt;-<span class="st"> </span><span class="fl">0.2</span>
omega_n &lt;-<span class="st"> </span><span class="kw">rlnorm</span>(T, <span class="dv">0</span>, sigma)</code></pre>
<ul>
<li><p>** Step 2**: For <span class="math">\(t = 0, 1, 2, \ldots, T\)</span>, do:</p></li>
<li><p>Solve:</p></li>
</ul>
<p><span class="math">\[V_t(S_t) = \max_{x_t \in \chi_t} \left(C(S_t, x_t) + \gamma \sum_{s^{\prime} \in \mathcal{S}} \mathbb{P}(s^{\prime} | S_t^n, x_t) V_{t+1}^{n-1} s^{\prime} \right)\]</span></p>
<p>That is, choose action <span class="math">\(x_t\)</span> that maximizes the value of the next step.</p>
<p>Let’s start with <span class="math">\(t=0\)</span>, <span class="math">\(n=1\)</span> and fix an <span class="math">\(x_0\)</span> from the set of <span class="math">\(\chi\)</span> (allowing the action space to be the same in each period, we can omit the subscript on <span class="math">\(\chi\)</span>) to get started. We first compute <span class="math">\(C(S_0, x_0)\)</span>.</p>
<p><span class="math">\(S_0 = S_0^1\)</span> which we fixed in step <strong>0b</strong> arbitrarily at 0.5.</p>
<p>The profits/costs <span class="math">\(C(S_t, x_t)\)</span> are the value derived by action (harvest) <span class="math">\(x_t\)</span> at state (stock) <span class="math">\(S_t\)</span>. Assuming a fixed price and no costs to harvesting, this is just whichever number is smaller (since we cannot harvest more than the available stock,</p>
<pre class="sourceCode r"><code class="sourceCode r">C &lt;-<span class="st"> </span>function(S, X) <span class="kw">pmin</span>(S, X)</code></pre>
<p>(where we have used R’s vectorized form of the min function).</p>
<p>This forward dynamic programming will still rely on the one-step transition matrix, <span class="math">\(\mathbb{P}\)</span>.</p>
<p>Let’s get the transition matrices for this problem, assuming log-normal noise,</p>
<pre class="sourceCode r"><code class="sourceCode r">sdp_matrix &lt;-<span class="st"> </span><span class="kw">determine_SDP_matrix</span>(f, p, <span class="dt">x_grid=</span>S, <span class="dt">h_grid=</span>chi, sigma_g)</code></pre>
<p>Which is a list of matrices, one for each harvest (action) <span class="math">\(x_t\)</span>.</p>
<p>Then we want to consider a fixed <span class="math">\(S_t^n\)</span> and fixed <span class="math">\(x_t\)</span>, and take the sum of <span class="math">\(\mathbb{P}(s^{\prime} | S_t^n, x_t)\)</span> over the <span class="math">\(s^{\prime}\)</span>, which means we want the <span class="math">\(x_t\)</span> element from the list, and then we need sum over the distribution of future states given the current state <span class="math">\(S_t^n\)</span>, e.g. a row of the matrix, e.g. <code>sdp_matrix[[x]][s,]</code>, which we (vector) multiply by <span class="math">\(V_{t+1}^{n-1}(s^{\prime})\)</span>.</p>
<p>This value <span class="math">\(V\)</span> is of course unknown, other than our initial random guess <span class="math">\(V_{t}^0\)</span>.<br />As we step through the iterations <span class="math">\(V_t^1\)</span>, <span class="math">\(V_t^2\)</span>, <span class="math">\(V_t^3\)</span>, etc., this should convgerge to something meaningful.</p>
<p>Note that the index along <span class="math">\(S\)</span> corresponding to <span class="math">\(S_t^n\)</span> is given by</p>
<pre class="sourceCode r"><code class="sourceCode r">s &lt;-<span class="st"> </span><span class="kw">which.min</span>(<span class="kw">abs</span>(S-S_0))</code></pre>
<p>So our maximization across <span class="math">\(x\)</span> just involves:</p>
<pre class="sourceCode r"><code class="sourceCode r">values &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">sapply</span>(<span class="dv">1</span>:<span class="kw">length</span>(chi), function(x)
    <span class="kw">C</span>(S[s], chi[x]) +<span class="st"> </span>sdp_matrix[[x]][s,] %*%<span class="st"> </span>V
)

max_x &lt;-<span class="st"> </span><span class="kw">which.max</span>(values)
v_hat &lt;-<span class="st"> </span><span class="kw">max</span>(values)</code></pre>
<p>Trivially, this is just the harvest level that maximizes <span class="math">\(C\)</span> so far (which is just harvesting the <span class="math">\(S_0\)</span>, since <span class="math">\(\bar V^0_t\)</span> begins at zero:</p>
<pre class="sourceCode r"><code class="sourceCode r">chi[max_x]</code></pre>
<pre><code>[1] 0.5</code></pre>
<ul>
<li>step <strong>2b</strong> We can now update our <span class="math">\(\bar V^0_t\)</span> to get <span class="math">\(\bar V^1_t\)</span>, using the rule:</li>
</ul>
<p><span class="math">\[V_t^n(S_t) = \begin{cases} 
\hat v_t^n &amp; S_t = S_t^n \\
\bar V_t^{n-1}(S_t) &amp; \textrm{otherwise} 
\end{cases}\]</span></p>
<p>e.g. use our maximum value for the case of the state we just considered <span class="math">\(S_t = S_t^n\)</span>, otherwise leave <span class="math">\(V_t\)</span> unchanged. Our new <span class="math">\(V\)</span> is thus:</p>
<pre class="sourceCode r"><code class="sourceCode r">V[s] =<span class="st"> </span>v_hat</code></pre>
<ul>
<li>step <strong>2c</strong> Compute <span class="math">\(S^n_{t+1} = S^M(S_t^n, x^n_t, W_{t+1}(\omega^n))\)</span></li>
</ul>
<p>We compute the next state using our <code>max_x</code> for <span class="math">\(x^n_t\)</span>, our random samples and the transition function…</p>
<pre class="sourceCode r"><code class="sourceCode r">S_1 &lt;-<span class="st"> </span>omega_n[<span class="dv">1</span>] *<span class="st"> </span><span class="kw">f</span>(S_0, chi[hat[<span class="st">&quot;x_nt&quot;</span>]], p)</code></pre>
<ul>
<li><strong>Step 3</strong> Let <span class="math">\(n = n+1\)</span>. if <span class="math">\(n &lt; N\)</span>, go to step 1</li>
</ul>
<h2 id="putting-this-all-together-as-a-recursive-algorithm">Putting this all together as a recursive algorithm</h2>
<pre class="sourceCode r"><code class="sourceCode r">N &lt;-<span class="st"> </span><span class="dv">5000</span> <span class="co"># iterations</span>
M &lt;-<span class="st"> </span><span class="dv">20</span> <span class="co"># gridsize </span>
Tmax &lt;-<span class="st"> </span><span class="dv">5</span> <span class="co"># Time horizon</span>

gamma &lt;-<span class="st"> </span><span class="fl">0.95</span> <span class="co"># Discount</span>
<span class="co"># f (defined above) </span>
<span class="co"># p  (defined above)</span>

sigma_g &lt;-<span class="st"> </span><span class="fl">0.5</span> <span class="co"># larger variation in random draws helps</span>
chi &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">length.out =</span> M)
S &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">length.out =</span> M)

sdp_matrix &lt;-<span class="st"> </span><span class="kw">determine_SDP_matrix</span>(f, p, <span class="dt">x_grid=</span>S, <span class="dt">h_grid=</span>chi, sigma_g)

V &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">1</span>, M, Tmax)  <span class="co"># A* strategy</span>
<span class="co"># Fails to explore at matrix(0, M, Tmax)</span>
<span class="co"># consider: # V &lt;- matrix(rep(chi, Tmax), nrow=M) # </span>
<span class="co"># V[,1] &lt;- chi   # fails to explore if it doesn&#39;t have at least some non-zero values</span>

C &lt;-<span class="st"> </span>function(S, X) <span class="kw">pmin</span>(S, X)
S_0 &lt;-<span class="st"> </span><span class="fl">0.5</span> 
alpha &lt;-<span class="st"> </span><span class="dv">1</span> <span class="co"># learning rate</span>


for(n in <span class="dv">1</span>:N){
  
  omega_n &lt;-<span class="st"> </span><span class="kw">rlnorm</span>(Tmax, <span class="dv">0</span>, sigma_g)
  S_current &lt;-<span class="st"> </span>S_0 <span class="co">#runif(1,0,1) # explores faster when this is random</span>

  for(t in <span class="dv">1</span>:Tmax){
    <span class="co"># index of the state we&#39;re considering</span>
    s &lt;-<span class="st"> </span><span class="kw">which.min</span>(<span class="kw">abs</span>(S-S_current)) 
    
    <span class="co"># Find the action maximizing the value</span>
    values &lt;-<span class="st"> </span><span class="kw">sapply</span>(<span class="dv">1</span>:<span class="kw">length</span>(chi), function(x)
      <span class="kw">C</span>(S[s], chi[x]) +<span class="st"> </span>gamma *<span class="st"> </span>sdp_matrix[[x]][s,] %*%<span class="st"> </span>V[,t])
    hat &lt;-<span class="st">  </span><span class="kw">c</span>(<span class="dt">x_nt =</span> <span class="kw">which.max</span>(values), <span class="dt">v_nt =</span> <span class="kw">max</span>(values))

    <span class="co"># Update value V as mixture of new value and previous value</span>
    V[hat[<span class="st">&quot;x_nt&quot;</span>], t] &lt;-<span class="st"> </span>(<span class="dv">1</span> -<span class="st"> </span>alpha) *<span class="st"> </span>V[hat[<span class="st">&quot;x_nt&quot;</span>],t] +<span class="st"> </span>alpha *<span class="st"> </span>hat[<span class="st">&quot;v_nt&quot;</span>] 
    
    <span class="co"># Advance the state in time along random path  </span>
    S_current &lt;-<span class="st"> </span>omega_n[t] *<span class="st"> </span><span class="kw">f</span>(S_current, chi[hat[<span class="st">&quot;x_nt&quot;</span>]], p)

  }
}</code></pre>
<p>for comparison: the SDP solution</p>
<pre class="sourceCode r"><code class="sourceCode r">opt &lt;-<span class="st"> </span><span class="kw">find_dp_optim</span>(sdp_matrix, S, chi, <span class="dv">70</span>, <span class="fl">0.5</span>, C, <span class="dv">1</span>-gamma, <span class="dt">reward=</span><span class="dv">0</span>)
opt$V</code></pre>
<pre><code> [1] 0.000 7.173 7.375 7.496 7.584 7.653 7.710 7.760 7.810 7.860 7.910
[12] 7.960 8.010 8.060 8.110 8.160 8.210 8.260 8.310 8.360</code></pre>
<h3 id="problems-arising-from-the-discretization">Problems arising from the discretization</h3>
<p>Note that after the first iteration, <span class="math">\(n=1\)</span>, the value matrix <span class="math">\(V\)</span> is no longer all zeros. There is a single state, <span class="math">\(S = S_0 =\)</span> 0.5, at which we have value. That value is lost if we set harvest <span class="math">\(x\)</span> too high, since we know we will not then end up in that state – from whence comes the incentive to consider future value. Unfortunately, the value exists only if we hit that state exactly – all other states are assumed to have zero value still.</p>
<h3 id="additional-problems">Additional problems</h3>
<p>We no longer have the loop-over-all-states problem, but we face several new or remaining issues:</p>
<ol type="1">
<li><p>We still require the use of the one-step transition matrix, with the equally troublesome sum over all states <span class="math">\(\sum_{s^{\prime}\in S} \mathbb{P}(s^{\prime} | S_t^n, x_t)\)</span>.<br />We will fix this by approximating the transitions in step 2b using random draws as well.</p></li>
<li><p>We only update the values of states we visit. We still need a way to estimate the value of states we have not visited.</p></li>
<li><p>Worse, we might not visit states that seem bad relative to states we have visited. This is particularly atrocious in this example. Since we initialize the value of all states at 0, the algorithm prefers to harvest all stock from the current state rather than risk a transition into a state starting at 0. There is no convergence guarentee that we will ever escape this cycle of avoiding states we have not seen. We can alter the initial guess of the value of course, and we could alter the starting condition to better explore.</p></li>
</ol>
<h2 id="extensions">Extensions</h2>
<p>The rest of the ADP development is designed to tackle each of these issues. This algorithm gives very poor performance, but very flexible skeleton on which to extend features that have made ADP such a successful approach for impossibly large problems.</p>
<h3 id="stochastic-value-function-sampling">Stochastic value function sampling</h3>
<p>Dealing with problem 1:</p>
<p><span class="math">\[V_t(S_t) = \max_{x_t \in \chi_t} \left(C(S_t, x_t) + \gamma \sum_{\hat \omega \in \hat \Omega^n_{t+1}} p_t+1(\hat \omega) \bar V_{t+1}^{n-1} (S_{t+1}) \right)\]</span></p>
<pre class="sourceCode r"><code class="sourceCode r">    V[hat[<span class="st">&quot;x_nt&quot;</span>], t] &lt;-<span class="st"> </span>(<span class="dv">1</span> -<span class="st"> </span>alpha) *<span class="st"> </span>
<span class="st">                         </span>V[hat[<span class="st">&quot;x_nt&quot;</span>],t] +<span class="st"> </span>
<span class="st">                          </span>alpha *<span class="st"> </span>hat[<span class="st">&quot;v_nt&quot;</span>] </code></pre>
<h3 id="decreasing-the-state-space-size">Decreasing the state space size</h3>
<ul>
<li>Aggregation</li>
<li>Continuous Value function approximations</li>
<li>Using the post-decision state variable (improves dealing with the expectation calc)</li>
</ul>
<h3 id="initialization-problem">Initialization problem</h3>
<ul>
<li>We do not explore if we are too pessimistic about value of visiting other states. Start optimisitc: AI’s A* alogrithm (synchronous)</li>
<li>Asynchronous updating – randomly sampling starting variables</li>
<li>RTDP (Real Time Dynamic Programming – not necessarily what it sounds like) external rule determines which states we visit</li>
</ul>
<h3 id="learning">Learning</h3>
<ul>
<li>The concepts of learning and the trade-off between exploration and exploitation are already built-in to the forward algorithm.</li>
</ul>
<h3 id="using-non-stochastic-transition-information-only-step-2b-can-be-written-as">Using Non-stochastic transition information only, step <strong>2b</strong> can be written as:</h3>
<p>Taking <span class="math">\(x_0\)</span> as the smallest harvest, <span class="math">\(\min(\chi)\)</span> = 0 and evaluating <span class="math">\(C(S_0,X_0) = \min(S_0, X_0)\)</span> gives us 0, rather trivially.<br />The next terms depend on the value <span class="math">\(\tilde V^0_1(s^{\prime})\)</span> for all <span class="math">\(s^{\prime} \in S\)</span>, which we have no idea about. Fortunately we have assumed a value for each of these in step 0a.</p>
<p>We must also come up with some values for the probability <span class="math">\(\mathbb{P}(s^{\prime} | S_1^0, x_1)\)</span> for each state, given our current state <span class="math">\(S_1^0\)</span> and considered action <span class="math">\(x_1\)</span>. This is more straight forward, since it is determined by our one-step transition function (without simulation - recall that the single step transition is given exactly).</p>
<p>To do so, we evaluate the argument for each value in our action space, <span class="math">\(x_t \in \chi_t\)</span>,</p>
<pre class="sourceCode r"><code class="sourceCode r">s &lt;-<span class="st"> </span>S_0
C &lt;-<span class="st"> </span>function(S, X) <span class="kw">pmin</span>(S, X)
arg &lt;-<span class="st"> </span><span class="kw">sapply</span>(chi, function(x) <span class="kw">C</span>(s, x) +<span class="st"> </span><span class="kw">f</span>(S, x, p) %*%<span class="st"> </span>V)
x_nt =<span class="st"> </span><span class="kw">which.max</span>(arg)
v_nt =<span class="st"> </span><span class="kw">max</span>(arg)
V[x_nt] =<span class="st"> </span>v_nt</code></pre>

    </article>
  </div>
  <div class="col-md-4">
    <div class="sidebar">
      <aside prefix="og:https://ogp.me/ns/article#">
  <p> <i class="icon-calendar"></i>
    <time datetime="2013-05-27 00:00:00 +0000" 
    property="dc:created">27 May 2013</time></p>
   

 <br />

  
	<p><a class="btn btn-default" rel="prev" href='/2013/05/24/notes.html'><i class="icon-chevron-left"></i> prev</a>
  
  
  <a class="btn btn-default" rel="next" href='/2013/05/28/notes.html'>next <i class="icon-chevron-right"></i></a></p>
  

  <br />

  <p> <a  onclick="recordOutboundLink(this, 'Outbound Links', 'history'); 
            return false;" 
          class="btn btn-default" 
          href="https://github.com/cboettig/2013/commits/master/_posts/2013-05-27-exploring-approximate-dynamic-programming-approaches.md"><i class="icon-time"></i> history</a></p>

  <br />

  <p><i class="icon-list"></i> Posted in 
     
      <a rel="dc:subject" class="category" 
         href="/2013/categories.html#ecology">ecology</a>
    
    </p>

  <p> <i class="icon-tag"></i> tags: 
    
    <!-- https://schema.org/BlogPosting/keywords -->
    <a rel="og:tag" class="tag" 
			href="/2013/tags.html#nonparametric-bayes">#nonparametric-bayes</a>, 
    
    <!-- https://schema.org/BlogPosting/keywords -->
    <a rel="og:tag" class="tag" 
			href="/2013/tags.html#algorithms">#algorithms</a>
    </p>

  <br/>

  

  <br/>
  <p><small> <i class="icon-barcode"></i> SHA Hash: <a href="https://github.com/cboettig/2013/commit/59f30f0a72a3822c10bab78804e271a0a416cf4c/_posts/2013-05-27-exploring-approximate-dynamic-programming-approaches.md"> 59f30f0a72a3822c10bab78804e271a0a416cf4c</a></small></p>
    
  <br/>
  
     <script src="/assets/js/toggleR.js"></script>
     <button class="btn btn-default" type="button" onclick="toggle_R();">Hide/Show Source</button>
  

</aside>

    </div>
  </div>
</div>

      <!-- Disqus Comments -->
      <div class="row disqus">
        <div class="col-md-8">          
            <div id="disqus_thread"></div>
            <script type="text/javascript">
                var disqus_shortname = 'cboettig'; // required: replace example with your forum shortname
                /* * * DON'T EDIT BELOW THIS LINE * * */
                (function() {
                    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
                    dsq.src = 'https://' + disqus_shortname + '.disqus.com/embed.js';
                    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
                })();
            </script>
            <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
        </div>
      </div>






      <footer class="footer">

<!--************** FOAF information to social networks ***************************** -->
  <div class="row">
    <div class="col-md-3 col-xs-4 socialicons" style="font-size:20px" typeof="foaf:Person" about="https://www.carlboettiger.info#me">
      <p>
          <script type="text/javascript" src="/assets/js/obfuscate-email-link.js"></script> 

          <a rel="foaf:account" href="https://twitter.com/cboettig" 
             onclick="recordOutboundLink(this, 'Outbound Links', 'Twitter'); 
             return false;"><span class="showtooltip" title="follow me on twitter (reading, discussing)"><i class="fa fa-twitter"></i></span></a> 

          <a rel="foaf:account" href="https://github.com/cboettig" 
             onclick="recordOutboundLink(this, 'Outbound Links', 'Github'); 
             return false;"><span class="showtooltip" title="follow me on Github (code, research)"><i class="fa fa-github"></i></span></a>
      <!--
          <a rel="foaf:account" href="https://plus.google.com/" 
             onclick="recordOutboundLink(this, 'Outbound Links', 'GPlus'); 
             return false;"><i class="fa fa-google-plus"></i></a>

          <a rel="foaf:account" href="https://www.mendeley.com/profiles/carl-boettiger" 
             onclick="recordOutboundLink(this, 'Outbound Links', 'Mendeley'); 
             return false;"><img src="/assets/img/icon-mendeley.png" /></a> 

           citations on google-scholar

           stackoverflow
      -->
      <a rel="foaf:weblog" type="application/atom+xml" href="/blog.xml"  
         class="showtooltip" title="RSS feeds for my blog-style entries. See the feed on my lab notebook (/atom.xml) to follow all entries instead." 
         onclick="recordOutboundLink(this, 'Outbound Links', 'RSS'); 
         return false;"><i class="fa fa-rss"></i></a>
       </p>
    </div>

    
    <!--**************** End social links **************************** -->


    <div class="col-md-4 col-md-offset-1 col-xs-4">
      <p><a onclick="recordOutboundLink(this, 'Outbound Links', 'ONS_claim'); return false;" href="https://onsclaims.wikispaces.com/"><img src="/assets/img/ons-aci2-icon.svg" alt="ONS" class="showtooltip" title="An Open Notebook Science (ONS) project claim: Entry provides all content (AC) immediately (I) or without significant delay.  See link for details"/></a></p>
    </div>


    <div class="col-md-3 col-md-offset-1 col-xs-4">
      <p>
      <a rel="license" property="https://creativecommons.org/ns#license" href="http://creativecommons.org/publicdomain/zero/1.0/" onclick="recordOutboundLink(this, 'Outbound Links', 'CC0'); return false;"><img src="/assets/img/cc-zero.svg" alt="CC0"/></a> 
      </p>
    </div>
  </div>


  
<!-- COinS metadata (for citation managers like Zotero etc), goes in body text -->
  <span
      class="Z3988" 
      title="ctx_ver=Z39.88-2004
      &amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Adc
      &amp;rfr_id=info%3Asid%2Focoins.info%3Agenerator
      &amp;rft.title=Exploring Approximate Dynamic Programming Approaches
      &amp;rft.creator=Carl Boettiger
      &amp;rft.date=2013-05-27
      &amp;rft.language=EN
      &amp;rft.rights=CC0
      &amp;rft_id=https://www.carlboettiger.info/05/27/exploring-approximate-dynamic-programming-approaches.html">
  </span>


</footer>




          <!-- Le javascript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->

    <!-- JQuery, used on a few pages (still?) -->
    <!-- <script type="text/javascript" src="/assets/js/jquery.js"></script> -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
    <!-- Equations using MathJax -->
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: {autoNumber: "all"} } });       </script>
    <!-- Twitter Bootstrap Javascript -->
    <!--  <script src="/assets/js/bootstrap.min.js"></script> -->
    <script src="//netdna.bootstrapcdn.com/bootstrap/3.1.1/js/bootstrap.min.js"></script>


    

        <script type="text/javascript">
          var _gaq = _gaq || [];
          _gaq.push(['_setAccount', 'UA-18401403-1']);
          _gaq.push(['_trackPageview']);
          (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'https://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
          })();
  </script>



<script type="text/javascript">
function recordOutboundLink(link, category, action) {
  try {
    var pageTracker=_gat._getTracker("UA-18401403-1");
    pageTracker._trackEvent(category, action);
    setTimeout('document.location = "' + link.href + '"', 100)
  }catch(err){}
}
</script>




    </div>
  </body>
</html>
   
